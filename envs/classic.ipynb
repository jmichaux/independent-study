{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from six import StringIO, b\n",
    "\n",
    "from gym import utils\n",
    "from gym.envs.toy_text import discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Evaluation\n",
    "\n",
    "##\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def policy_evaluation(policy, env, discount_factor=1.0, theta=1e-5):\n",
    "    # Start with a random (all 0) value function\n",
    "    V = np.zeros(env.nS)\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in range(env.nS-1):\n",
    "            v = 0\n",
    "            # Look at the possible next actions\n",
    "            for a, action_prob in enumerate(policy[s]):\n",
    "                # For each action, look at the possible next states...\n",
    "                for  prob, next_state, reward, done in env.P[s][a]:\n",
    "                    v += action_prob * prob * (reward + discount_factor * V[next_state])               \n",
    "            # How much our value function changed (across any states)\n",
    "            delta = max(delta, np.abs(v - V[s]))\n",
    "            V[s] = v\n",
    "        # Stop evaluating once our value function change is below a threshold\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return np.array(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Sutton example 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Norvig and Russel Chapters 17 and 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.81155822  0.86780822  0.91780822  1.        ]\n",
      " [ 0.76155822  0.          0.66027397 -1.        ]\n",
      " [ 0.70530821  0.65530819  0.6114155   0.38792488]]\n"
     ]
    }
   ],
   "source": [
    "env = ClassicGridEnv3x4(nrew=-0.04)\n",
    "policy = np.array([\n",
    "    [0.0, 0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0, 0.0],\n",
    "\n",
    "    [0.0, 0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 0.0, 1.0],\n",
    "\n",
    "    [0.0, 0.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0, 0.0],\n",
    "    [1.0, 0.0, 0.0, 0.0],\n",
    "])\n",
    "\n",
    "print(policy_evaluation(policy, env)[:-1].reshape((3,4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: CS229 Lecture 16 (32:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.52265227  0.73215214  0.76664901  1.        ]\n",
      " [-0.89853345  0.         -0.82069941 -1.        ]\n",
      " [-0.88462607 -0.86880465 -0.85452188 -0.99511395]]\n"
     ]
    }
   ],
   "source": [
    "env = ClassicGridEnv3x4(nrew=-0.02)\n",
    "policy = np.array([\n",
    "    [0.0, 0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0, 0.0],\n",
    "\n",
    "    [0.0, 1.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 1.0],\n",
    "\n",
    "    [0.0, 0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 1.0],\n",
    "    [0.0, 0.0, 0.0, 1.0],\n",
    "])\n",
    "\n",
    "print(policy_evaluation(policy, env, 0.99)[:-1].reshape((3,4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Improvement\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "\n",
    "MAPS = {\n",
    "    \"3x4\": [\n",
    "        \"EEEG\",\n",
    "        \"EXEH\",\n",
    "        \"SEEE\",\n",
    "    ],\n",
    "    \"4x4\": [\n",
    "        \"GEEE\",\n",
    "        \"EEEE\",\n",
    "        \"EEEE\",\n",
    "        \"EEEG\",\n",
    "    ],\n",
    "    \"5x4\": [\n",
    "        \"GEEE\",\n",
    "        \"EEEE\",\n",
    "        \"EEEE\",\n",
    "        \"EEEG\",\n",
    "        \"XEXX\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "class ClassicGridEnv(discrete.DiscreteEnv):\n",
    "    \"\"\"\n",
    "    Example Gridworld:\n",
    "\n",
    "        EEEG\n",
    "        EXEH\n",
    "        SEEE\n",
    "\n",
    "    S : starting cell\n",
    "    E : empty cell\n",
    "    H : hole\n",
    "    G : goal\n",
    "    X : obstacle\n",
    "\n",
    "    The episode ends when the agent reaches a terminal state (goal or pit). The agent\n",
    "    receives a reward when transitioning in the environment. See below for details.\n",
    "\n",
    "    Rewards r(s, a, s'):\n",
    "        3x4:\n",
    "            r(goal,any action, s') = 1\n",
    "            r(pit, any action, s') = -1,\n",
    "            r(nonterminal state, any action, s') =  -0.1\n",
    "\n",
    "        4x4 or 5x4:\n",
    "            r(nonterminal state, any action, s') =  -1\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {'render.modes': ['human', 'ansi']}\n",
    "\n",
    "\n",
    "    def __init__(self, desc=None, map_name=None, is_noisy=False, nrew=-0.1):\n",
    "        if desc is None and map_name is None:\n",
    "            raise ValueError('Must provide either desc or map_name')\n",
    "        elif desc is None:\n",
    "            desc = MAPS[map_name]\n",
    "        self.desc = desc = np.asarray(desc, dtype='c')\n",
    "        self.nrow, self.ncol = nrow, ncol = desc.shape\n",
    "        self.reward_range = (-1, 1)\n",
    "\n",
    "        nA = 4\n",
    "        nS = nrow * ncol \n",
    "        nS+=1\n",
    "        \n",
    "        #initial state distribution\n",
    "        isd = np.array(desc == b'S').astype('float64').ravel()\n",
    "        isd /= isd.sum()\n",
    "\n",
    "        # Empty dict of dict of lists for environment dynamics\n",
    "        P = {s: {a : [] for a in range(nA)} for s in range(nS)}\n",
    "        # Terminal state\n",
    "        P[-1] = {\n",
    "        0: [(1.0, -1, 0.0, True)],\n",
    "        1: [(1.0, -1, 0.0, True)],\n",
    "        2: [(1.0, -1, 0.0, True)],\n",
    "        3: [(1.0, -1, 0.0, True)]\n",
    "        }\n",
    "\n",
    "        def to_s(row, col):\n",
    "            return row*ncol + col\n",
    "\n",
    "        def inc(row, col, a):\n",
    "            # left\n",
    "            if a == 0:\n",
    "                col = max(col-1, 0)\n",
    "            # down\n",
    "            if a == 1:\n",
    "                row = min(row+1, nrow-1)\n",
    "            # right\n",
    "            if a == 2:\n",
    "                col = min(col+1, ncol-1)\n",
    "            if a == 3:\n",
    "                row = max(row-1, 0)\n",
    "            return (row, col)\n",
    "\n",
    "        # create state-transition probabilities\n",
    "        for row in range(nrow):\n",
    "            for col in range(ncol):\n",
    "                s = to_s(row, col)\n",
    "                for a in range(nA):\n",
    "                    li = P[s][a]\n",
    "                    letter = desc[row, col]\n",
    "                    if letter == b'G':\n",
    "                        li.append((1.0, -1, 1, False))\n",
    "                    elif letter == b'H':\n",
    "                        li.append((1.0, -1, -1, False))\n",
    "                    elif letter == b'X':\n",
    "                        li.append((0.0, s, 0, False))\n",
    "                    else:\n",
    "                        if is_noisy:\n",
    "                            for b in [(a-1)%4, a, (a+1)%4]:\n",
    "                                newrow, newcol = inc(row, col, b)\n",
    "                                newletter = desc[newrow, newcol]\n",
    "                                if newletter == b'X':\n",
    "                                    newrow, newcol = row, col\n",
    "                                    newletter = desc[newrow, newcol]\n",
    "                                newstate = to_s(newrow, newcol)\n",
    "                                done = bytes(newletter) in b'GH'\n",
    "                                done = False\n",
    "                                rew = nrew\n",
    "                                li.append((0.8 if b == a else 0.1, newstate, rew, done))\n",
    "                        else:\n",
    "                            newrow, newcol = inc(row, col, a)\n",
    "                            newletter = desc[newrow, newcol]\n",
    "                            if newletter == b'X':\n",
    "                                newrow, newcol = row, col\n",
    "                                newletter = desc[newrow, newcol]\n",
    "                            newstate = to_s(newrow, newcol)\n",
    "                            newletter = desc[newrow, newcol]\n",
    "                            done = bytes(newletter) in b'GH'\n",
    "                            if map_name == \"3x4\":\n",
    "                                rew = float(newletter == b'G') - float(newletter == b'H') + nrew * (float(newletter != b'G') * float(newletter != b'H'))\n",
    "                            else:\n",
    "                                rew = float(newletter == b'G') - 1\n",
    "                            li.append((1.0, newstate, rew, done))\n",
    "\n",
    "        super(ClassicGridEnv, self).__init__(nS, nA, P, isd)\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        outfile = StringIO() if mode == 'ansi' else sys.stdout\n",
    "\n",
    "        row, col = self.s // self.ncol, self.s % self.ncol\n",
    "        desc = self.desc.tolist()\n",
    "        desc = [[c.decode('utf-8') for c in line] for line in desc]\n",
    "        desc[row][col] = utils.colorize(desc[row][col], \"red\", highlight=True)\n",
    "        if self.lastaction is not None:\n",
    "            outfile.write(\"  ({})\\n\".format([\"Left\",\"Down\",\"Right\",\"Up\"][self.lastaction]))\n",
    "        else:\n",
    "            outfile.write(\"\\n\")\n",
    "        outfile.write(\"\\n\".join(''.join(line) for line in desc)+\"\\n\")\n",
    "\n",
    "        if mode != 'human':\n",
    "            return outfile\n",
    "\n",
    "\n",
    "class ClassicGridEnv3x4(ClassicGridEnv):\n",
    "    def __init__(self, nrew):\n",
    "        super(ClassicGridEnv3x4, self).__init__(map_name=\"3x4\", is_noisy=True, nrew=nrew)\n",
    "\n",
    "class ClassicGridEnv4x4(ClassicGridEnv):\n",
    "    def __init__(self):\n",
    "        super(ClassicGridEnv4x4, self).__init__(map_name=\"4x4\", is_noisy=False)\n",
    "\n",
    "class ClassicGridEnv5x4Static(ClassicGridEnv):\n",
    "    \"\"\"\n",
    "    Do not allow agent to move from cell 13 to cell 15 (17 in array).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ClassicGridEnv5x4Static, self).__init__(map_name=\"5x4\", is_noisy=False)\n",
    "        self.P[13][1] =  [(1.0, 13, -1.0, False)]\n",
    "        # State 15 is state 17\n",
    "        self.P[17] = {\n",
    "        0: [(1.0, 12, -1.0, False)],\n",
    "        1: [(1.0, 17, -1.0, False)],\n",
    "        2: [(1.0, 14, -1.0, False)],\n",
    "        3: [(1.0, 13, -1.0, False)]\n",
    "        }\n",
    "\n",
    "class ClassicGridEnv5x4Dynamic(ClassicGridEnv):\n",
    "    \"\"\"\n",
    "    Allow agent to move from cell 13 to cell 15 (17 in array).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ClassicGridEnv5x4Dynamic, self).__init__(map_name=\"5x4\", is_noisy=False)\n",
    "        self.P[17] = {\n",
    "        0: [(1.0, 12, -1.0, False)],\n",
    "        1: [(1.0, 17, -1.0, False)],\n",
    "        2: [(1.0, 14, -1.0, False)],\n",
    "        3: [(1.0, 13, -1.0, False)]\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
